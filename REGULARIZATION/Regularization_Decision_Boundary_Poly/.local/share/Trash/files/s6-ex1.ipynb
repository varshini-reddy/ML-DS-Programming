{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9grnGSASGOwm"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import scipy.optimize as opt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DfKkJbAXGOwq"
   },
   "outputs": [],
   "source": [
    "# Load the file \"land_type.csv\" into a dataframe\n",
    "\n",
    "df = pd.read_csv(\"land_type.csv\")\n",
    "\n",
    "# Assign the variable 'X' to the predictors & 'y' to the response \n",
    "\n",
    "X = df.drop(\"land_type\", axis=1).values\n",
    "\n",
    "y = df['land_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validatio nsets\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "uPcUXJ84GOww",
    "outputId": "59f8b22f-5d64-4dc3-bb6c-653ea5f68452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= [0.62]\n",
      "Accuracy= [0.62, 0.76]\n",
      "Accuracy= [0.62, 0.76, 0.76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= [0.62, 0.76, 0.76, 0.66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= [0.62, 0.76, 0.76, 0.66, 0.66]\n",
      "Accuracy= [0.62, 0.76, 0.76, 0.66, 0.66, 0.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Make a logistic regression model with below given C value\n",
    "\n",
    "degree = 10\n",
    "\n",
    "#Make a list of 6 C values to vary the range of regularization such that you get the best accuracy\n",
    "\n",
    "Clist = [1e-15,1e-5,1e-3,1,1e3,1e5]\n",
    "\n",
    "\n",
    "validation_accuracy = []\n",
    "\n",
    "for i in Clist:\n",
    "    \n",
    "    lr = LogisticRegression(C=i, max_iter=16000)\n",
    "\n",
    "    # Use Polynomial features to make a response variable of degree 10\n",
    "    X_poly_train = PolynomialFeatures(degree).fit_transform(X_train)\n",
    "\n",
    "    X_poly_val = PolynomialFeatures(degree).fit_transform(X_val)\n",
    "    lr.fit(X_poly_train, y_train)\n",
    "\n",
    "    y_val_pred = lr.predict(X_poly_val)\n",
    "\n",
    "    validation_accuracy.append(accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "    print(\"Accuracy=\",validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best C value from the list above is 1e-05\n"
     ]
    }
   ],
   "source": [
    "# Find the C value associated with the highest accuracy\n",
    "\n",
    "best_C = Clist[validation_accuracy.index(max(validation_accuracy))]\n",
    "\n",
    "print(f\"The best C value from the list above is {best_C}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "\n",
    "Now, to visualise the regularisation, use the helper code below to plot the decision boundaries for each clist chosen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SsfQ6JKOGOwz"
   },
   "outputs": [],
   "source": [
    "# The below helper function from session 5 exercise 4, 'plot_boundary' plots the boundary for a given logistic regression function\n",
    "\n",
    "def plot_boundary(x, y, model, title, ax, plot_data=True, fill=True, color='Greens',degree=0):\n",
    "    \n",
    "    if plot_data:\n",
    "        # PLOT DATA\n",
    "        ax.scatter(x[y==1,0], x[y==1,1], c='green')\n",
    "        ax.scatter(x[y==0,0], x[y==0,1], c='brown')\n",
    "    \n",
    "    # CREATE MESH\n",
    "    interval = np.arange(min(x.min(), y.min()),max(x.max(), y.max()),0.01)\n",
    "    n = np.size(interval)\n",
    "    x1, x2 = np.meshgrid(interval, interval)\n",
    "    x1 = x1.reshape(-1,1)\n",
    "    x2 = x2.reshape(-1,1)\n",
    "    xx = np.concatenate((x1, x2), axis=1)\n",
    "\n",
    "    # PREDICT ON MESH POINTS\n",
    "    xxpoly = PolynomialFeatures(degree).fit_transform(xx)\n",
    "    yy = model.predict(xxpoly)    \n",
    "    yy = yy.reshape((n, n))\n",
    "\n",
    "    # PLOT DECISION SURFACE\n",
    "    x1 = x1.reshape(n, n)\n",
    "    x2 = x2.reshape(n, n)\n",
    "    if fill:\n",
    "        ax.contourf(x1, x2, yy, alpha=0.5, cmap=color)\n",
    "    else:\n",
    "        ax.contour(x1, x2, yy, alpha=0.5, cmap=color)\n",
    "    \n",
    "    # LABEL AXIS, TITLE\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Latitude')\n",
    "    ax.set_ylabel('Longitude')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t011IstIGOw2"
   },
   "outputs": [],
   "source": [
    "# The helper function below, fits a Logistic Regression model, and plots the boundary around it using the function above\n",
    "\n",
    "def fit_and_plot_dt(x, y, c, title, ax, plot_data=True, fill=True, color='Blues',degree=0):\n",
    "\n",
    "    lreg = LogisticRegression(C=c, max_iter=6000)\n",
    "\n",
    "    x1 = PolynomialFeatures(degree).fit_transform(x)\n",
    "    lreg.fit(x1, y)\n",
    "\n",
    "    # PLOT DECISION TREE BOUNDARY\n",
    "    ax = plot_boundary(x, y, lreg, title, ax, plot_data, fill, color,degree=degree)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: No contour levels were found within the data range.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: No contour levels were found within the data range.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to visualise the regularisation\n",
    "\n",
    "fig, ax = plt.subplots(nrows=int(len(Clist)/2), ncols=2,figsize=(12, 10))\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i,d in enumerate(Clist):\n",
    "\n",
    "    ax[i] = fit_and_plot_dt(X, y, d, 'Satellite',ax[i], plot_data=True, fill=False,degree=6) \n",
    "    ax[i].set_xlim(-6, 6)\n",
    "    ax[i].set_ylim(-6, 6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "s5_e4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
